{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "A0r_rm8lu6OE"
   },
   "source": [
    "\"\"\"\n",
    "Dataset: https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
    "\n",
    "Use packages like keras, scikit-learn and tensorflow to build a neural network classifier that predicts whether or not a patient has diabetes.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbOPF4qVIMgN"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-wrkQFswvCzE"
   },
   "source": [
    "# read in data and split into feature vectors and classifications\n",
    "filepath = 'https://static.junilearning.com/ai_level_2/diabetes.csv'\n",
    "# dataset: https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
    "data = pd.read_csv(filepath)\n",
    "X = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]\n",
    "\n",
    "# X.head()\n",
    "# y.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JlUejFjnvOu5"
   },
   "source": [
    "# split into testing and training data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_Evy4A_ZvUZi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "319ec1c8-2b8b-43bb-bd15-cb0c4dd4668e"
   },
   "source": [
    "# build a sequential neural net\n",
    "# first layer takes in a vector of size 8 (the feature vector size), has 20 nodes and activation function relu\n",
    "# second layer has 12 nodes and activation function relu\n",
    "# third layer has 1 node and uses the sigmoid activation function\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=8, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=300, validation_split=0.2, batch_size=10)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "46/46 [==============================] - 1s 12ms/step - loss: 4.7100 - accuracy: 0.5291 - val_loss: 2.4648 - val_accuracy: 0.3534\n",
      "Epoch 2/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.8977 - accuracy: 0.4511 - val_loss: 1.5519 - val_accuracy: 0.4052\n",
      "Epoch 3/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.3178 - accuracy: 0.4197 - val_loss: 1.1503 - val_accuracy: 0.5345\n",
      "Epoch 4/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 1.0442 - accuracy: 0.4805 - val_loss: 0.9050 - val_accuracy: 0.5948\n",
      "Epoch 5/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.8351 - accuracy: 0.5490 - val_loss: 1.0724 - val_accuracy: 0.6466\n",
      "Epoch 6/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.8787 - accuracy: 0.5660 - val_loss: 0.6931 - val_accuracy: 0.6466\n",
      "Epoch 7/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.7916 - accuracy: 0.5504 - val_loss: 0.6743 - val_accuracy: 0.6552\n",
      "Epoch 8/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.7131 - accuracy: 0.6127 - val_loss: 0.6854 - val_accuracy: 0.5690\n",
      "Epoch 9/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.7467 - accuracy: 0.5981 - val_loss: 0.7988 - val_accuracy: 0.6379\n",
      "Epoch 10/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.6028 - val_loss: 0.6956 - val_accuracy: 0.6466\n",
      "Epoch 11/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.7037 - val_loss: 0.6597 - val_accuracy: 0.6379\n",
      "Epoch 12/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6156 - val_loss: 0.6683 - val_accuracy: 0.6983\n",
      "Epoch 13/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.6433 - val_loss: 0.6411 - val_accuracy: 0.7155\n",
      "Epoch 14/300\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.6602 - val_loss: 0.6246 - val_accuracy: 0.7155\n",
      "Epoch 15/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7080 - val_loss: 0.6748 - val_accuracy: 0.7069\n",
      "Epoch 16/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.6883 - val_loss: 0.6353 - val_accuracy: 0.7069\n",
      "Epoch 17/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.6729 - val_loss: 0.5523 - val_accuracy: 0.7414\n",
      "Epoch 18/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7251 - val_loss: 0.5760 - val_accuracy: 0.7241\n",
      "Epoch 19/300\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7129 - val_loss: 0.5725 - val_accuracy: 0.6983\n",
      "Epoch 20/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.7036 - val_loss: 0.5751 - val_accuracy: 0.7155\n",
      "Epoch 21/300\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.7169 - val_loss: 0.5540 - val_accuracy: 0.7241\n",
      "Epoch 22/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.7070 - val_loss: 0.6042 - val_accuracy: 0.6983\n",
      "Epoch 23/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.7153 - val_loss: 0.5541 - val_accuracy: 0.7069\n",
      "Epoch 24/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6859 - val_loss: 0.5517 - val_accuracy: 0.6983\n",
      "Epoch 25/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.7123 - val_loss: 0.5733 - val_accuracy: 0.7155\n",
      "Epoch 26/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.6911 - val_loss: 0.5686 - val_accuracy: 0.7069\n",
      "Epoch 27/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.6885 - val_loss: 0.6044 - val_accuracy: 0.6724\n",
      "Epoch 28/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.6747 - val_loss: 0.5652 - val_accuracy: 0.7155\n",
      "Epoch 29/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7610 - val_loss: 0.5673 - val_accuracy: 0.6983\n",
      "Epoch 30/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.6980 - val_loss: 0.6186 - val_accuracy: 0.6810\n",
      "Epoch 31/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7248 - val_loss: 0.5373 - val_accuracy: 0.7155\n",
      "Epoch 32/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7109 - val_loss: 0.6351 - val_accuracy: 0.6983\n",
      "Epoch 33/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7129 - val_loss: 0.5451 - val_accuracy: 0.7500\n",
      "Epoch 34/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7336 - val_loss: 0.6067 - val_accuracy: 0.6983\n",
      "Epoch 35/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6694 - val_loss: 0.6146 - val_accuracy: 0.7414\n",
      "Epoch 36/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6829 - val_loss: 0.6351 - val_accuracy: 0.7155\n",
      "Epoch 37/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.6856 - val_loss: 0.5978 - val_accuracy: 0.6810\n",
      "Epoch 38/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7342 - val_loss: 0.6281 - val_accuracy: 0.7069\n",
      "Epoch 39/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.6960 - val_loss: 0.5860 - val_accuracy: 0.6983\n",
      "Epoch 40/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.6864 - val_loss: 0.5288 - val_accuracy: 0.7155\n",
      "Epoch 41/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7440 - val_loss: 0.5421 - val_accuracy: 0.7069\n",
      "Epoch 42/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7348 - val_loss: 0.5539 - val_accuracy: 0.7155\n",
      "Epoch 43/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7252 - val_loss: 0.5757 - val_accuracy: 0.7069\n",
      "Epoch 44/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7194 - val_loss: 0.5797 - val_accuracy: 0.7155\n",
      "Epoch 45/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7149 - val_loss: 0.5904 - val_accuracy: 0.7069\n",
      "Epoch 46/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7328 - val_loss: 0.5357 - val_accuracy: 0.6983\n",
      "Epoch 47/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7340 - val_loss: 0.5403 - val_accuracy: 0.7155\n",
      "Epoch 48/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7003 - val_loss: 0.5758 - val_accuracy: 0.7328\n",
      "Epoch 49/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7284 - val_loss: 0.5437 - val_accuracy: 0.7069\n",
      "Epoch 50/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7055 - val_loss: 0.5315 - val_accuracy: 0.7414\n",
      "Epoch 51/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7477 - val_loss: 0.5123 - val_accuracy: 0.7328\n",
      "Epoch 52/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7073 - val_loss: 0.5612 - val_accuracy: 0.7155\n",
      "Epoch 53/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.8061 - val_loss: 0.5553 - val_accuracy: 0.7328\n",
      "Epoch 54/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7436 - val_loss: 0.5029 - val_accuracy: 0.7414\n",
      "Epoch 55/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7373 - val_loss: 0.5209 - val_accuracy: 0.7155\n",
      "Epoch 56/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7904 - val_loss: 0.5649 - val_accuracy: 0.7414\n",
      "Epoch 57/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.6884 - val_loss: 0.5178 - val_accuracy: 0.7155\n",
      "Epoch 58/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7523 - val_loss: 0.6616 - val_accuracy: 0.6293\n",
      "Epoch 59/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7060 - val_loss: 0.5239 - val_accuracy: 0.7328\n",
      "Epoch 60/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7021 - val_loss: 0.5627 - val_accuracy: 0.7328\n",
      "Epoch 61/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7614 - val_loss: 0.6271 - val_accuracy: 0.7069\n",
      "Epoch 62/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.6940 - val_loss: 0.5246 - val_accuracy: 0.7414\n",
      "Epoch 63/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7491 - val_loss: 0.5327 - val_accuracy: 0.7328\n",
      "Epoch 64/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7641 - val_loss: 0.5159 - val_accuracy: 0.7586\n",
      "Epoch 65/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7679 - val_loss: 0.6058 - val_accuracy: 0.7414\n",
      "Epoch 66/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7536 - val_loss: 0.5123 - val_accuracy: 0.7414\n",
      "Epoch 67/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7287 - val_loss: 0.5699 - val_accuracy: 0.7500\n",
      "Epoch 68/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.6673 - val_loss: 0.5187 - val_accuracy: 0.7586\n",
      "Epoch 69/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7536 - val_loss: 0.5075 - val_accuracy: 0.7414\n",
      "Epoch 70/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7471 - val_loss: 0.5093 - val_accuracy: 0.7328\n",
      "Epoch 71/300\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7558 - val_loss: 0.5183 - val_accuracy: 0.7155\n",
      "Epoch 72/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7930 - val_loss: 0.5002 - val_accuracy: 0.7586\n",
      "Epoch 73/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7646 - val_loss: 0.5663 - val_accuracy: 0.7328\n",
      "Epoch 74/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7296 - val_loss: 0.5496 - val_accuracy: 0.7241\n",
      "Epoch 75/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7710 - val_loss: 0.6548 - val_accuracy: 0.6552\n",
      "Epoch 76/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7458 - val_loss: 0.4891 - val_accuracy: 0.7414\n",
      "Epoch 77/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7363 - val_loss: 0.5009 - val_accuracy: 0.7414\n",
      "Epoch 78/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7493 - val_loss: 0.5333 - val_accuracy: 0.7414\n",
      "Epoch 79/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7455 - val_loss: 0.5017 - val_accuracy: 0.7586\n",
      "Epoch 80/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7766 - val_loss: 0.5851 - val_accuracy: 0.7241\n",
      "Epoch 81/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7341 - val_loss: 0.5100 - val_accuracy: 0.7414\n",
      "Epoch 82/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7616 - val_loss: 0.5075 - val_accuracy: 0.7414\n",
      "Epoch 83/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7233 - val_loss: 0.5465 - val_accuracy: 0.7155\n",
      "Epoch 84/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7303 - val_loss: 0.5242 - val_accuracy: 0.7241\n",
      "Epoch 85/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7360 - val_loss: 0.7287 - val_accuracy: 0.6897\n",
      "Epoch 86/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.7189 - val_loss: 0.6656 - val_accuracy: 0.7069\n",
      "Epoch 87/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7742 - val_loss: 0.5304 - val_accuracy: 0.7069\n",
      "Epoch 88/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7270 - val_loss: 0.5849 - val_accuracy: 0.6983\n",
      "Epoch 89/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7054 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 90/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7636 - val_loss: 0.7131 - val_accuracy: 0.6552\n",
      "Epoch 91/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7418 - val_loss: 0.5447 - val_accuracy: 0.7328\n",
      "Epoch 92/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7283 - val_loss: 0.5157 - val_accuracy: 0.7672\n",
      "Epoch 93/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7618 - val_loss: 0.5216 - val_accuracy: 0.7586\n",
      "Epoch 94/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7447 - val_loss: 0.5160 - val_accuracy: 0.7672\n",
      "Epoch 95/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7985 - val_loss: 0.5136 - val_accuracy: 0.7241\n",
      "Epoch 96/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7321 - val_loss: 0.5337 - val_accuracy: 0.7328\n",
      "Epoch 97/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7455 - val_loss: 0.5443 - val_accuracy: 0.7155\n",
      "Epoch 98/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7515 - val_loss: 0.6725 - val_accuracy: 0.6897\n",
      "Epoch 99/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7445 - val_loss: 0.6603 - val_accuracy: 0.7155\n",
      "Epoch 100/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7893 - val_loss: 0.5154 - val_accuracy: 0.7241\n",
      "Epoch 101/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7619 - val_loss: 0.5120 - val_accuracy: 0.7328\n",
      "Epoch 102/300\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7524 - val_loss: 0.5765 - val_accuracy: 0.7328\n",
      "Epoch 103/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7691 - val_loss: 0.5150 - val_accuracy: 0.7155\n",
      "Epoch 104/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7418 - val_loss: 0.5509 - val_accuracy: 0.7155\n",
      "Epoch 105/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7480 - val_loss: 0.6003 - val_accuracy: 0.7241\n",
      "Epoch 106/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7619 - val_loss: 0.5195 - val_accuracy: 0.7069\n",
      "Epoch 107/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7984 - val_loss: 0.4845 - val_accuracy: 0.7759\n",
      "Epoch 108/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7698 - val_loss: 0.6143 - val_accuracy: 0.7155\n",
      "Epoch 109/300\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7884 - val_loss: 0.5268 - val_accuracy: 0.7586\n",
      "Epoch 110/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7729 - val_loss: 0.6137 - val_accuracy: 0.6897\n",
      "Epoch 111/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7278 - val_loss: 0.5717 - val_accuracy: 0.7241\n",
      "Epoch 112/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7872 - val_loss: 0.6069 - val_accuracy: 0.7414\n",
      "Epoch 113/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7805 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
      "Epoch 114/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7772 - val_loss: 0.4979 - val_accuracy: 0.7672\n",
      "Epoch 115/300\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7505 - val_loss: 0.5852 - val_accuracy: 0.6810\n",
      "Epoch 116/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7245 - val_loss: 0.5658 - val_accuracy: 0.7414\n",
      "Epoch 117/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7857 - val_loss: 0.5040 - val_accuracy: 0.7586\n",
      "Epoch 118/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7780 - val_loss: 0.5377 - val_accuracy: 0.7414\n",
      "Epoch 119/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7732 - val_loss: 0.4977 - val_accuracy: 0.7328\n",
      "Epoch 120/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7581 - val_loss: 0.5271 - val_accuracy: 0.7586\n",
      "Epoch 121/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7799 - val_loss: 0.4845 - val_accuracy: 0.7500\n",
      "Epoch 122/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7512 - val_loss: 0.5697 - val_accuracy: 0.7500\n",
      "Epoch 123/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7801 - val_loss: 0.5023 - val_accuracy: 0.7414\n",
      "Epoch 124/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7798 - val_loss: 0.5485 - val_accuracy: 0.7414\n",
      "Epoch 125/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7555 - val_loss: 0.5190 - val_accuracy: 0.7155\n",
      "Epoch 126/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7457 - val_loss: 0.5399 - val_accuracy: 0.7414\n",
      "Epoch 127/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7826 - val_loss: 0.5550 - val_accuracy: 0.6897\n",
      "Epoch 128/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7393 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 129/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7936 - val_loss: 0.5650 - val_accuracy: 0.7155\n",
      "Epoch 130/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7454 - val_loss: 0.5508 - val_accuracy: 0.7328\n",
      "Epoch 131/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7555 - val_loss: 0.5054 - val_accuracy: 0.7414\n",
      "Epoch 132/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7195 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 133/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7880 - val_loss: 0.4994 - val_accuracy: 0.7328\n",
      "Epoch 134/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7601 - val_loss: 0.5795 - val_accuracy: 0.7155\n",
      "Epoch 135/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7937 - val_loss: 0.6317 - val_accuracy: 0.7155\n",
      "Epoch 136/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7682 - val_loss: 0.4854 - val_accuracy: 0.7414\n",
      "Epoch 137/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7532 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
      "Epoch 138/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7652 - val_loss: 0.5274 - val_accuracy: 0.7500\n",
      "Epoch 139/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7507 - val_loss: 0.5352 - val_accuracy: 0.7241\n",
      "Epoch 140/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7884 - val_loss: 0.5783 - val_accuracy: 0.7414\n",
      "Epoch 141/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7551 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
      "Epoch 142/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7893 - val_loss: 0.5673 - val_accuracy: 0.7155\n",
      "Epoch 143/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.8182 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 144/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.8191 - val_loss: 0.5592 - val_accuracy: 0.7069\n",
      "Epoch 145/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7898 - val_loss: 0.5668 - val_accuracy: 0.6897\n",
      "Epoch 146/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7701 - val_loss: 0.5490 - val_accuracy: 0.7414\n",
      "Epoch 147/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8100 - val_loss: 0.5188 - val_accuracy: 0.7241\n",
      "Epoch 148/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8064 - val_loss: 0.5989 - val_accuracy: 0.7241\n",
      "Epoch 149/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.8037 - val_loss: 0.6183 - val_accuracy: 0.6724\n",
      "Epoch 150/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7693 - val_loss: 0.5369 - val_accuracy: 0.6810\n",
      "Epoch 151/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7751 - val_loss: 0.4792 - val_accuracy: 0.7500\n",
      "Epoch 152/300\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7824 - val_loss: 0.5575 - val_accuracy: 0.7586\n",
      "Epoch 153/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7985 - val_loss: 0.5522 - val_accuracy: 0.7241\n",
      "Epoch 154/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7940 - val_loss: 0.4847 - val_accuracy: 0.7586\n",
      "Epoch 155/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8083 - val_loss: 0.6168 - val_accuracy: 0.7069\n",
      "Epoch 156/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8077 - val_loss: 0.5104 - val_accuracy: 0.7155\n",
      "Epoch 157/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7808 - val_loss: 0.6219 - val_accuracy: 0.7155\n",
      "Epoch 158/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7862 - val_loss: 0.6098 - val_accuracy: 0.7241\n",
      "Epoch 159/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.8118 - val_loss: 0.5090 - val_accuracy: 0.6983\n",
      "Epoch 160/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7632 - val_loss: 0.5083 - val_accuracy: 0.7759\n",
      "Epoch 161/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7827 - val_loss: 0.5004 - val_accuracy: 0.7328\n",
      "Epoch 162/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7653 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 163/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7971 - val_loss: 0.5665 - val_accuracy: 0.7069\n",
      "Epoch 164/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.8061 - val_loss: 0.4982 - val_accuracy: 0.7759\n",
      "Epoch 165/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7875 - val_loss: 0.4891 - val_accuracy: 0.7241\n",
      "Epoch 166/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7569 - val_loss: 0.5549 - val_accuracy: 0.7328\n",
      "Epoch 167/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7653 - val_loss: 0.4888 - val_accuracy: 0.7586\n",
      "Epoch 168/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.8096 - val_loss: 0.5501 - val_accuracy: 0.7414\n",
      "Epoch 169/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7753 - val_loss: 0.6279 - val_accuracy: 0.7241\n",
      "Epoch 170/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7958 - val_loss: 0.6277 - val_accuracy: 0.6897\n",
      "Epoch 171/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.8166 - val_loss: 0.5206 - val_accuracy: 0.7241\n",
      "Epoch 172/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7644 - val_loss: 0.5257 - val_accuracy: 0.6983\n",
      "Epoch 173/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7831 - val_loss: 0.4846 - val_accuracy: 0.7500\n",
      "Epoch 174/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7915 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 175/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8337 - val_loss: 0.5139 - val_accuracy: 0.7586\n",
      "Epoch 176/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7772 - val_loss: 0.5092 - val_accuracy: 0.7414\n",
      "Epoch 177/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.8255 - val_loss: 0.5177 - val_accuracy: 0.7155\n",
      "Epoch 178/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7761 - val_loss: 0.4889 - val_accuracy: 0.7069\n",
      "Epoch 179/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8147 - val_loss: 0.5142 - val_accuracy: 0.7069\n",
      "Epoch 180/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.5339 - val_accuracy: 0.7328\n",
      "Epoch 181/300\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7897 - val_loss: 0.4857 - val_accuracy: 0.7414\n",
      "Epoch 182/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7576 - val_loss: 0.5285 - val_accuracy: 0.7155\n",
      "Epoch 183/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7645 - val_loss: 0.5198 - val_accuracy: 0.7328\n",
      "Epoch 184/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8105 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
      "Epoch 185/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7670 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 186/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7793 - val_loss: 0.5333 - val_accuracy: 0.7672\n",
      "Epoch 187/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8097 - val_loss: 0.4857 - val_accuracy: 0.7414\n",
      "Epoch 188/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8006 - val_loss: 0.5348 - val_accuracy: 0.7241\n",
      "Epoch 189/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8077 - val_loss: 0.5119 - val_accuracy: 0.7155\n",
      "Epoch 190/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7962 - val_loss: 0.6149 - val_accuracy: 0.6897\n",
      "Epoch 191/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7901 - val_loss: 0.6078 - val_accuracy: 0.7414\n",
      "Epoch 192/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7964 - val_loss: 0.5017 - val_accuracy: 0.7155\n",
      "Epoch 193/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7837 - val_loss: 0.5059 - val_accuracy: 0.7328\n",
      "Epoch 194/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7974 - val_loss: 0.5178 - val_accuracy: 0.7414\n",
      "Epoch 195/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8381 - val_loss: 0.5541 - val_accuracy: 0.7414\n",
      "Epoch 196/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7507 - val_loss: 0.4879 - val_accuracy: 0.7155\n",
      "Epoch 197/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8223 - val_loss: 0.5008 - val_accuracy: 0.7155\n",
      "Epoch 198/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8100 - val_loss: 0.5403 - val_accuracy: 0.7069\n",
      "Epoch 199/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7560 - val_loss: 0.5364 - val_accuracy: 0.7586\n",
      "Epoch 200/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8215 - val_loss: 0.5294 - val_accuracy: 0.7586\n",
      "Epoch 201/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8139 - val_loss: 0.5167 - val_accuracy: 0.7241\n",
      "Epoch 202/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.7708 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 203/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7836 - val_loss: 0.5734 - val_accuracy: 0.7414\n",
      "Epoch 204/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.8074 - val_loss: 0.5228 - val_accuracy: 0.7241\n",
      "Epoch 205/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7990 - val_loss: 0.5425 - val_accuracy: 0.7414\n",
      "Epoch 206/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8034 - val_loss: 0.5707 - val_accuracy: 0.7155\n",
      "Epoch 207/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7591 - val_loss: 0.5651 - val_accuracy: 0.7414\n",
      "Epoch 208/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8286 - val_loss: 0.5291 - val_accuracy: 0.7414\n",
      "Epoch 209/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8266 - val_loss: 0.5030 - val_accuracy: 0.7328\n",
      "Epoch 210/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8003 - val_loss: 0.4992 - val_accuracy: 0.7069\n",
      "Epoch 211/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7960 - val_loss: 0.5376 - val_accuracy: 0.7586\n",
      "Epoch 212/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7869 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 213/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8121 - val_loss: 0.5136 - val_accuracy: 0.7241\n",
      "Epoch 214/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.8185 - val_loss: 0.5362 - val_accuracy: 0.7759\n",
      "Epoch 215/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8086 - val_loss: 0.5405 - val_accuracy: 0.7414\n",
      "Epoch 216/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8011 - val_loss: 0.5254 - val_accuracy: 0.7586\n",
      "Epoch 217/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.7951 - val_loss: 0.5491 - val_accuracy: 0.7155\n",
      "Epoch 218/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7734 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 219/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8349 - val_loss: 0.6321 - val_accuracy: 0.7241\n",
      "Epoch 220/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7725 - val_loss: 0.5018 - val_accuracy: 0.7586\n",
      "Epoch 221/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7912 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 222/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8449 - val_loss: 0.5654 - val_accuracy: 0.7155\n",
      "Epoch 223/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.8126 - val_loss: 0.5295 - val_accuracy: 0.7155\n",
      "Epoch 224/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8103 - val_loss: 0.5376 - val_accuracy: 0.7155\n",
      "Epoch 225/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8357 - val_loss: 0.5190 - val_accuracy: 0.7586\n",
      "Epoch 226/300\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7675 - val_loss: 0.5425 - val_accuracy: 0.7586\n",
      "Epoch 227/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8183 - val_loss: 0.5345 - val_accuracy: 0.7414\n",
      "Epoch 228/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.5191 - val_accuracy: 0.7069\n",
      "Epoch 229/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8254 - val_loss: 0.5034 - val_accuracy: 0.7155\n",
      "Epoch 230/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8228 - val_loss: 0.5122 - val_accuracy: 0.7672\n",
      "Epoch 231/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.7854 - val_loss: 0.5223 - val_accuracy: 0.7672\n",
      "Epoch 232/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8193 - val_loss: 0.5195 - val_accuracy: 0.7414\n",
      "Epoch 233/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8171 - val_loss: 0.5975 - val_accuracy: 0.7414\n",
      "Epoch 234/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7793 - val_loss: 0.5287 - val_accuracy: 0.7586\n",
      "Epoch 235/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8118 - val_loss: 0.5412 - val_accuracy: 0.7414\n",
      "Epoch 236/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8560 - val_loss: 0.5443 - val_accuracy: 0.7414\n",
      "Epoch 237/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8121 - val_loss: 0.5346 - val_accuracy: 0.7069\n",
      "Epoch 238/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8010 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 239/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8046 - val_loss: 0.5538 - val_accuracy: 0.7414\n",
      "Epoch 240/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.7992 - val_loss: 0.5247 - val_accuracy: 0.7500\n",
      "Epoch 241/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8290 - val_loss: 0.5053 - val_accuracy: 0.7328\n",
      "Epoch 242/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8418 - val_loss: 0.5994 - val_accuracy: 0.7155\n",
      "Epoch 243/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8109 - val_loss: 0.5254 - val_accuracy: 0.7586\n",
      "Epoch 244/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3825 - accuracy: 0.8355 - val_loss: 0.5313 - val_accuracy: 0.7328\n",
      "Epoch 245/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8094 - val_loss: 0.5553 - val_accuracy: 0.7586\n",
      "Epoch 246/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.8033 - val_loss: 0.5108 - val_accuracy: 0.7414\n",
      "Epoch 247/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8124 - val_loss: 0.5331 - val_accuracy: 0.7241\n",
      "Epoch 248/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7930 - val_loss: 0.5297 - val_accuracy: 0.7069\n",
      "Epoch 249/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7972 - val_loss: 0.5118 - val_accuracy: 0.7328\n",
      "Epoch 250/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8150 - val_loss: 0.6115 - val_accuracy: 0.7241\n",
      "Epoch 251/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8276 - val_loss: 0.5608 - val_accuracy: 0.7414\n",
      "Epoch 252/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8425 - val_loss: 0.5433 - val_accuracy: 0.7241\n",
      "Epoch 253/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7834 - val_loss: 0.6069 - val_accuracy: 0.7414\n",
      "Epoch 254/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8347 - val_loss: 0.6020 - val_accuracy: 0.7241\n",
      "Epoch 255/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8195 - val_loss: 0.5644 - val_accuracy: 0.7328\n",
      "Epoch 256/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8484 - val_loss: 0.5833 - val_accuracy: 0.7500\n",
      "Epoch 257/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.7927 - val_loss: 0.5839 - val_accuracy: 0.7328\n",
      "Epoch 258/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8118 - val_loss: 0.5727 - val_accuracy: 0.7500\n",
      "Epoch 259/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7966 - val_loss: 0.6010 - val_accuracy: 0.6983\n",
      "Epoch 260/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.7860 - val_loss: 0.6256 - val_accuracy: 0.7241\n",
      "Epoch 261/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8299 - val_loss: 0.5620 - val_accuracy: 0.7586\n",
      "Epoch 262/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.7933 - val_loss: 0.5619 - val_accuracy: 0.7414\n",
      "Epoch 263/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8258 - val_loss: 0.5436 - val_accuracy: 0.7414\n",
      "Epoch 264/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8213 - val_loss: 0.5558 - val_accuracy: 0.7500\n",
      "Epoch 265/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8199 - val_loss: 0.5572 - val_accuracy: 0.7328\n",
      "Epoch 266/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7983 - val_loss: 0.5487 - val_accuracy: 0.7414\n",
      "Epoch 267/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8414 - val_loss: 0.6032 - val_accuracy: 0.7328\n",
      "Epoch 268/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8260 - val_loss: 0.5867 - val_accuracy: 0.7586\n",
      "Epoch 269/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7944 - val_loss: 0.5106 - val_accuracy: 0.7586\n",
      "Epoch 270/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7972 - val_loss: 0.5450 - val_accuracy: 0.7586\n",
      "Epoch 271/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3754 - accuracy: 0.8050 - val_loss: 0.6141 - val_accuracy: 0.7241\n",
      "Epoch 272/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8423 - val_loss: 0.5379 - val_accuracy: 0.7328\n",
      "Epoch 273/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8266 - val_loss: 0.5426 - val_accuracy: 0.7241\n",
      "Epoch 274/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8119 - val_loss: 0.5533 - val_accuracy: 0.7500\n",
      "Epoch 275/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8346 - val_loss: 0.5716 - val_accuracy: 0.7586\n",
      "Epoch 276/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8358 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 277/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8082 - val_loss: 0.5474 - val_accuracy: 0.7155\n",
      "Epoch 278/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8274 - val_loss: 0.5501 - val_accuracy: 0.7414\n",
      "Epoch 279/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8326 - val_loss: 0.5554 - val_accuracy: 0.7414\n",
      "Epoch 280/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8335 - val_loss: 0.5956 - val_accuracy: 0.7586\n",
      "Epoch 281/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8298 - val_loss: 0.5862 - val_accuracy: 0.7414\n",
      "Epoch 282/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8056 - val_loss: 0.6027 - val_accuracy: 0.7586\n",
      "Epoch 283/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8065 - val_loss: 0.5839 - val_accuracy: 0.7328\n",
      "Epoch 284/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3825 - accuracy: 0.8320 - val_loss: 0.6373 - val_accuracy: 0.7328\n",
      "Epoch 285/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8490 - val_loss: 0.5878 - val_accuracy: 0.7500\n",
      "Epoch 286/300\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8185 - val_loss: 0.5718 - val_accuracy: 0.7414\n",
      "Epoch 287/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8387 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
      "Epoch 288/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7647 - val_loss: 0.6166 - val_accuracy: 0.7414\n",
      "Epoch 289/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8339 - val_loss: 0.5780 - val_accuracy: 0.7328\n",
      "Epoch 290/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8237 - val_loss: 0.5641 - val_accuracy: 0.7414\n",
      "Epoch 291/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8229 - val_loss: 0.5612 - val_accuracy: 0.7414\n",
      "Epoch 292/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8283 - val_loss: 0.6249 - val_accuracy: 0.7241\n",
      "Epoch 293/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.8557 - val_loss: 0.5749 - val_accuracy: 0.7328\n",
      "Epoch 294/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.8517 - val_loss: 0.5362 - val_accuracy: 0.7414\n",
      "Epoch 295/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.8495 - val_loss: 0.6033 - val_accuracy: 0.7759\n",
      "Epoch 296/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8555 - val_loss: 0.5853 - val_accuracy: 0.7500\n",
      "Epoch 297/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8133 - val_loss: 0.5941 - val_accuracy: 0.7155\n",
      "Epoch 298/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8109 - val_loss: 0.5813 - val_accuracy: 0.7328\n",
      "Epoch 299/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8400 - val_loss: 0.5997 - val_accuracy: 0.7414\n",
      "Epoch 300/300\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.7938 - val_loss: 0.5566 - val_accuracy: 0.7241\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3c6753d7d0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dcpP9oM0vX8m",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "287d73db-b3fc-448a-b336-d08e6875486c"
   },
   "source": [
    "# run on testing data and get accuracy\n",
    "print(model.evaluate(x_test, y_test)[1])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 0.7877 - accuracy: 0.7031\n",
      "0.703125\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YxBkQ2dKv8gc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fc44d077-23b1-4e2d-a6e9-f0a5e3b257cc"
   },
   "source": [
    "# see predictions of the testing data\n",
    "predictions = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "print(predictions)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}
